<!DOCTYPE html> 
<html>
<head>
    <meta charset="UTF-8">
    <title>Document</title>
</head>
<body>
    
    <!-- 标题标签 -->
     <h1>这是我建的第一个网页。</h1>
     <h2>这是我建的第一个网页。</h2>
     <h3 id="top">这是我建的第一个网页。</h3>

     <!-- 换行标签 <br> -->
    换行标签换行标签<br>换行标签换行标签

    <!-- 段落标签 -->
    <p>Generating creative combinatorial objects from two object texts poses a significant challenge 
    for the text-to-image synthesis, often hindered by a focus on emulating existing
    data distributions. In this paper, we develop a straightforward yet highly
    effective method, called balance swap-sampling.
    First, we propose a swapping mechanism that generates a novel combinatorial
    object image set by randomly exchanging intrinsic elements of two text embeddings
    through a cutting-edge diffusion model. Second, we introduce a balance swapping
    region to efficiently sample a small subset from the newly generated image set
    by managing balance CLIP distances between the new images and their original generations,
    increasing the likelihood of accepting the high-quality combinations. Last, we employ a
    segmentation method to compare CLIP distances among the segmented components, ultimately
    selecting the most promising object from the sampled subset. Our experiments on text pairs
    of objects from ImageNet showcase that our approach outperforms recent SOTA T2I methods,
    even the associated concepts appear to be implausible, such as lionfish-abacus,
    and monarch-cheetah.</p>
    <p>Generating creative combinatorial objects from two object texts poses a significant challenge 
        for the text-to-image synthesis, often hindered by a focus on emulating existing
        data distributions. In this paper, we decond, we introduce a balance swapping
        region to efficiently sample a small subset from the newly generated image set
        by managing balance CLIP distances between the new images and their original generations,
        increasing the likelihood of accepting the high-quality combinations. Last, we employ a
        segmentation method to compare CLIP distances among the segmented components, ultimately
        selecting the most promising object from the sampled subset. Our experiments on text pairs
        of objects from ImageNet showcase that our approach outperforms recent SOTA T2I methods,
        even the associated concepts appear to be implausible, such as lionfish-abacus,
        and monarch-cheetah.</p>


    <!-- 水平线标签 hr -->
     <hr>

    <!-- 字体清洁标签 em -->
     <em>倾斜标签em</em>

    <!-- 字体加粗标签 strong -->
      <strong> 加粗 strong </strong>

    <!-- 图片标签 img -->
     <img src="./img/fig_0.jpg" alt="西鱼" width="300px">

    <!-- 超链接 锚链接 -->
     <br>
     <a href="#top"> 点我跳转
        <img src="./img/fig_0.jpg" alt="西鱼" width="300px"> </a>

</body>
</html>